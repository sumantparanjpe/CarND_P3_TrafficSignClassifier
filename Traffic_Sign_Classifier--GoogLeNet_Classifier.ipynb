{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "### Deep Learning Project: Build a Traffic Sign Recognition Classifier\n",
    "\n",
    "\n",
    "**Test data source & references**\n",
    "\n",
    "[German Traffic Sign Repo](benchmark.ini.rub.de/?section=gtsrb&subsection=dataset#Imageformat)\n",
    "\n",
    "\n",
    "### Project Rubric\n",
    "\n",
    "The project rubric and submission guidelines is available [here](./TrafficSignProjectRubric.pdf). All items have been addressed withoin the notebooks submitted. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Data Process & Visualization\n",
    "\n",
    ">**Note**: <span style=\"color:red\">Please run the notebook [here](./Traffic_Sign_Classifier--Data_Pre-process.ipynb) before proceeding with the classifier network below.</span> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. GoogLeNet Classifier\n",
    "\n",
    "This program reads pre-processed data from pickled data-source and applies the GoogLeNet Inceptionv3 model for traffic sign classification.\n",
    "The TensorFlow model is then pickled in the `./models` sub-directory for the final evaluation phase.  \n",
    "\n",
    ">**Strategy**: \n",
    "> 1. Training hyper-parameters were selected afetr a fair amount  of parameter sweeps but essentially are empirircal in the choice. The set values in this notebook perform with goo accuracy for the particular data-sets chosen for validation & testing. \n",
    "> 2. A drop-out regularization scheme is chosen as in the stndard Inceptionv3-based Googlenet arhcitecture. \n",
    "> 3. An early training termination crietria was chosen to be when per-epoch training accuracy (measured on validation set) was found to decrease by $\\le \\epsilon=10^{-3}$. This was done primarily to shorten training wall-clock times for a model with *sufficient* accuracy for the particular classifier task.  \n",
    "> 4. Note that the early termination kicks in only after _a minimum number of epochs_ (chosen here to be $E = 15$) have been run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import packages required for notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import datetime\n",
    "import time\n",
    "import pickle\n",
    "import csv\n",
    "import random\n",
    "import os\n",
    "import math\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.contrib.layers import flatten\n",
    "import tensorflow.contrib.layers as layers\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "print(\"Packages imported ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.1 Load Pickled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(X, arrayname = ''):\n",
    "    print(arrayname, \": {StdDev, Mean, Range, Min, Max} =\\n\\t\",X.std(axis=(0,1,2)), X.mean(axis=(0,1,2)), X.ptp(), X.min(axis=(0,1,2)), X.max(axis=(0,1,2)))    \n",
    "    return\n",
    "\n",
    "# Load pickled normalized-data\n",
    "pickle_file = './dataset/Trafficsigns_NormalizedDataSet.p'\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    pickle_data = pickle.load(f)\n",
    "    y_trn = pickle_data['train_labels']\n",
    "    X_train_size = pickle_data['train_size']\n",
    "    X_train_loc = pickle_data['train_roi']\n",
    "    X_trn = pickle_data['trn_norm']\n",
    "    X_train_gray_norm = pickle_data['train_gray_norm']\n",
    "    \n",
    "    y_val = pickle_data['valid_labels']\n",
    "    X_valid_size = pickle_data['valid_size']\n",
    "    X_valid_loc = pickle_data['valid_roi']\n",
    "    X_val = pickle_data['val_norm']\n",
    "    X_valid_gray_norm = pickle_data['valid_gray_norm']\n",
    "    \n",
    "    y_tst = pickle_data['test_labels']\n",
    "    X_test_size = pickle_data['test_size']\n",
    "    X_test_loc = pickle_data['test_roi']\n",
    "    X_tst = pickle_data['tst_norm']\n",
    "    X_test_gray_norm = pickle_data['test_gray_norm']\n",
    "\n",
    "    signname_hash = pickle_data['signname_hash']\n",
    "\n",
    "    del pickle_data  # Free up memory\n",
    "\n",
    "#\n",
    "# Dataset summary\n",
    "#\n",
    "total_samples = len(X_trn)+len(X_val)+len(X_tst)\n",
    "n_classes = len(set(y_trn))\n",
    "n_test = len(X_tst)\n",
    "n_train = len(X_trn)\n",
    "n_validation = len(X_val)\n",
    "\n",
    "print(\"Unique labels = \",len(set(y_trn)))\n",
    "print(\"Training set: \")\n",
    "print(\"\\t Number of samples = \",len(X_trn), \":({0:.2f}%)\".format(len(X_trn)/total_samples*100))\n",
    "print(\"\\t Image dimension   = \",X_trn.shape[1],\"x\", X_trn.shape[2],\"x\", X_trn.shape[3])\n",
    "print(\"\\t Data types (X, y) = \",X_trn.dtype,\",\", y_trn.dtype)\n",
    "print(\"\\t Data range (X, y) = \",np.ptp(X_trn),\",\", np.ptp(y_trn))\n",
    "print(\"Validation set: \")\n",
    "print(\"\\t Number of samples = \",len(X_val), \":({0:.2f}%)\".format(len(X_val)/total_samples*100))\n",
    "print(\"\\t Image dimension   = \",X_val.shape[1],\"x\", X_val.shape[2],\"x\", X_val.shape[3])\n",
    "print(\"\\t Data types (X, y) = \",X_val.dtype,\",\", y_val.dtype)\n",
    "print(\"\\t Data range (X, y) = \",np.ptp(X_val),\",\", np.ptp(y_val))\n",
    "print(\"Test set: \")\n",
    "print(\"\\t Number of samples = \",len(X_tst), \":({0:.2f}%)\".format(len(X_tst)/total_samples*100))\n",
    "print(\"\\t Image dimension   = \",X_tst.shape[1],\"x\", X_tst.shape[2],\"x\", X_tst.shape[3])\n",
    "print(\"\\t Data types (X, y) = \",X_tst.dtype,\",\", y_tst.dtype)\n",
    "print(\"\\t Data range (X, y) = \",np.ptp(X_tst),\",\", np.ptp(y_tst))\n",
    "\n",
    "print('Data loaded ...')\n",
    "\n",
    "print('\\nData Summary Statistics:')\n",
    "print_stats(X_trn, \"train\")\n",
    "print_stats(X_val, \"valid\")\n",
    "print_stats(X_tst, \"test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## 2.1 GoogLeNet Model Architecture\n",
    "\n",
    "Design and implement a deep learning model that learns to recognize traffic signs. Train and test your model on the [German Traffic Sign Dataset](http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset).\n",
    "\n",
    "There are various aspects to consider when thinking about this problem:\n",
    "\n",
    "- Neural network architecture (is the network over or underfitting?)\n",
    "- Play around preprocessing techniques (normalization, rgb to grayscale, etc)\n",
    "- Number of examples per label (some have more than others).\n",
    "- Generate fake data.\n",
    "\n",
    ">**Note**: No padding is required for this implementation as the normalized data-set has be re-sized to 32 x 32.\n",
    "\n",
    ">**Note**: RGB images are used here, set `USE_GRAYSCALE = True` to use gray-scaled versions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 TensorFlow Environment Hyper-Parameters\n",
    "\n",
    "Re-shuffle data-set to remove hidden biases in labelled sequences\n",
    "\n",
    "\n",
    "\n",
    "**Hyperparameter Record** \n",
    "\n",
    "> *GoogLeNet*: `USE_GRAYSCALE = False`, `EPOCHS = 35`, `BATCH_SIZE = 128`, `KEEP_PROB = .5`, `LEARN_RATE = 4e-4`, `USE_SGD = 'Adam'` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "\n",
    "USE_ARCH = 'GoogLeNet' # choose ML network {LeNet, GoogLeNet, AlexNet}\n",
    "USE_GRAYSCALE = False\n",
    "if (USE_GRAYSCALE):\n",
    "    in_ch = 1\n",
    "else:\n",
    "    in_ch = 3\n",
    "    \n",
    "if (USE_ARCH == 'LeNet'):\n",
    "    EPOCHS = 50\n",
    "    BATCH_SIZE = 128\n",
    "    KEEP_PROB = .85 # 0.5 # Dropout, probability to keep units\n",
    "    LEARN_RATE = 1e-3 # learning rate\n",
    "    USE_SGD = 'Adam' # {Adam, SGD}\n",
    "    EARLYTERM_EPS = 1e-3 # early termination threshold\n",
    "    MIN_EPOCHS = 15 # number fo epoch runs after early-termination check kicks in    \n",
    "elif (USE_ARCH == 'AlexNet'): \n",
    "    EPOCHS = 50\n",
    "    BATCH_SIZE = 128\n",
    "    KEEP_PROB = 0.5 # Dropout, probability to keep units\n",
    "    LEARN_RATE = 1e-3 # learning rate\n",
    "    USE_SGD = 'Adam' # {Adam, SGD}\n",
    "    BETA = 1e-4 # weight regularization factor\n",
    "elif (USE_ARCH == 'GoogLeNet'): \n",
    "    EPOCHS = 20\n",
    "    BATCH_SIZE = 128\n",
    "    KEEP_PROB = 0.5 # Dropout, probability to keep units\n",
    "    LEARN_RATE = 4e-4 # learning rate\n",
    "    USE_SGD = 'Adam' # {Adam, SGD}\n",
    "    EARLYTERM_EPS = 1e-3 # early termination threshold\n",
    "    MIN_EPOCHS = 15 # number of epoch runs after early-termination check kicks in    \n",
    "    \n",
    "if (USE_GRAYSCALE):    \n",
    "    X_trn, y_trn = shuffle(X_train_gray_norm, y_trn)\n",
    "    X_val, y_val = shuffle(X_valid_gray_norm, y_val)\n",
    "    X_tst, y_tst = shuffle(X_test_gray_norm, y_tst)\n",
    "else:\n",
    "    X_trn, y_trn = shuffle(X_trn, y_trn)\n",
    "    X_val, y_val = shuffle(X_val, y_val)\n",
    "    X_tst, y_tst = shuffle(X_tst, y_tst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.3 GoogLeNet Network (& Inception v3 Model)\n",
    "\n",
    "![GoogLeNet Architecture](./googlenet_archdiagram.png)\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "**Model Layer Architecture**\n",
    "\n",
    "Input data is a normalized RGB frame of size `32x32` pixels. The Inception v3 based GoogLeNet network base-layers can be used almost without modifications. The changes required are for the  final fully-connected layer to detect `n_classes` number of categories as well as some modifications to suit the in stead of the standard 10 categories from original implementation original implementation.  \n",
    "\n",
    "As implemented, the network below has the following layer organization: (derived from a Keras summary implementation of the network)  \n",
    ">**Note**:\n",
    "The following code has been used from the Keras documentation directly\n",
    "[Keras Application Inception v3](https://keras.io/applications/#inceptionv3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Keras Implementation of GoogLeNet for a summary description\n",
    "#\n",
    "#\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Input, Activation, Dropout\n",
    "from keras.applications import inception_v3\n",
    "\n",
    "model = Sequential()\n",
    "model = inception_v3.InceptionV3(include_top=False, weights=None, input_tensor=None, input_shape=None, classes=43)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## Using pre-trained GoogLeNEt (Inception v3) network\n",
    "base_model = application_inception_v3(weights = 'imagenet', include_top = FALSE)\n",
    "predictions = base_model$output > layer_global_average_pooling_2d() > layer_dense(units = 1024, activation = 'relu') > layer_dense(units = 200, activation = 'softmax') \n",
    "inception_v3_preprocess_input(x)\n",
    "\"\"\"\n",
    "\n",
    "def Inception(inputs, conv11_size, conv33_11_size, conv33_size,conv55_11_size, conv55_size, pool11_size):\n",
    "    conv11 = layers.conv2d(inputs, conv11_size, [1, 1])\n",
    "    conv33_reduce = layers.conv2d(inputs, conv33_11_size, [1, 1])\n",
    "    conv33 = layers.conv2d(conv33_reduce, conv33_size, [3, 3])\n",
    "    conv55_reduce = layers.conv2d(inputs, conv55_11_size, [1, 1])\n",
    "    conv55 = layers.conv2d(conv55_reduce, conv55_size, [5, 5])\n",
    "    pool_proj = layers.max_pool2d(inputs, [3, 3], stride = 1, padding='SAME')\n",
    "    pool11 = layers.conv2d(pool_proj, pool11_size, [1, 1])\n",
    "    #return tf.concat(3, [conv11, conv33, conv55, pool11]) # argument sequence in older TF versions\n",
    "    return tf.concat([conv11, conv33, conv55, pool11], 3) # argument sequence to match numpy in newer TF versions\n",
    "\n",
    "def GoogLeNet(inputs): # inputs size:32x32x3\n",
    "    conv1 = layers.conv2d(inputs, 64, [3, 3], stride = 2) # 16x16x64\n",
    "    \n",
    "    inception_2a = Inception(conv1, 64, 96, 128, 16, 32, 32) # 16x16x256\n",
    "    inception_2b = Inception(inception_2a, 128, 128, 192, 32, 96, 64) # 16x16x480\n",
    "    pool2 = layers.max_pool2d(inception_2b, [3, 3]) # 7x7x480 ? why\n",
    "    \n",
    "    inception_3a = Inception(pool2, 192, 96, 208, 16, 48, 64) # 7x7x512\n",
    "    inception_3b = Inception(inception_3a, 160, 112, 224, 24, 64, 64) # 7x7x512\n",
    "    pool3 = layers.max_pool2d(inception_3b, [3, 3]) # 3x3x512\n",
    "    \n",
    "    inception_4a = Inception(pool3, 256, 160, 320, 32, 128, 128) # 3x3x832\n",
    "    inception_4b = Inception(inception_4a, 384, 192, 384, 48, 128, 128) # 3x3x1024\n",
    "    pool4 = layers.avg_pool2d(inception_4b, [3, 3], stride = 1) \n",
    "\n",
    "    reshape = tf.reshape(pool4, [-1, 1024])\n",
    "    dropout = layers.dropout(reshape, KEEP_PROB)\n",
    "    logits = layers.fully_connected(dropout, 43, activation_fn=None)\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Features and Labels\n",
    "\n",
    "Train GoogLeNet to classify traffic-sign data.\n",
    "\n",
    "`x` is a placeholder for a batch of input images.\n",
    "`y` is a placeholder for a batch of output labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 32, 32, in_ch))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "one_hot_y = tf.one_hot(y, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Training Pipeline\n",
    "\n",
    "Create a training pipeline that uses the model to classify traffic-sign data.\n",
    "\n",
    "Using dropout (instead of L2 regularization) for weights-culling to avoid over-fitting (high-variance) of the model.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# choose network architecture to run\n",
    "logits = GoogLeNet(x)\n",
    "\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "if (USE_SGD == 'Adam'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = LEARN_RATE)\n",
    "elif (USE_SGD == 'SGD'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate = LEARN_RATE)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 Model Evaluation\n",
    "\n",
    "Evaluate how well the loss and accuracy of the model for a given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset + BATCH_SIZE], y_data[offset:offset + BATCH_SIZE]\n",
    "        accuracy, loss = sess.run([accuracy_operation, loss_operation], feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.4 Train & Validate the Model\n",
    "\n",
    "Run the training data through the training pipeline to train the model.\n",
    "\n",
    "Before each epoch, shuffle the training set.\n",
    "\n",
    "After each epoch, measure the loss and accuracy of the validation set.\n",
    "\n",
    "A validation set can be used to assess how well the model is performing. A low accuracy on the training and validation\n",
    "sets imply underfitting. A high accuracy on the training set but low accuracy on the validation set implies overfitting.\n",
    "\n",
    "Save the model after training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train your model here.\n",
    "### Calculate and report the accuracy on the training and validation set.\n",
    "### Once a final model architecture is selected, \n",
    "### the accuracy on the test set should be calculated and reported as well.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "t1_start = time.perf_counter()\n",
    "t2_start = time.process_time()\n",
    "\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "train_acc = []\n",
    "valid_acc = []\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "DONOT_TRAIN = False\n",
    "\n",
    "if (DONOT_TRAIN == False):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        num_examples = len(X_trn)\n",
    "\n",
    "        print(\"Training...{} samples\".format(num_examples))       \n",
    "        for i in range(EPOCHS):\n",
    "            X_trn, y_trn = shuffle(X_trn, y_trn)\n",
    "            total_train_acc = 0        \n",
    "            for offset in range(0, num_examples, BATCH_SIZE):\n",
    "                end = offset + BATCH_SIZE\n",
    "                batch_x, batch_y = X_trn[offset:end], y_trn[offset:end]\n",
    "                #batch_x = batch_x.reshape(len(batch_x), 32, 32, in_ch)\n",
    "                tacc, tloss = sess.run([training_operation, loss_operation], feed_dict={x: batch_x, y: batch_y})\n",
    "                train_loss.append(tloss)\n",
    "                train_acc.append(tacc)\n",
    "                \n",
    "            validation_accuracy, vloss = evaluate(X_val, y_val)\n",
    "            valid_loss.append(vloss)\n",
    "            valid_acc.append(validation_accuracy)\n",
    "            print(\"Epochs {:2.0%} done : Accuracy {:.3f}\".format((i+1)/EPOCHS, validation_accuracy), end=\"\\r\")\n",
    "            #\n",
    "            # check for early termination from epochs based on evolution of \"recent\" history of validation accuracy\n",
    "            #\n",
    "            \"\"\"\n",
    "            if (len(valid_acc) > MIN_EPOCHS): # only after minimum epochs have been run\n",
    "                if ((valid_acc[-1]>valid_acc[-2]) and \n",
    "                    (valid_acc[-2]>valid_acc[-3])): # check for monotonic increase                   \n",
    "                    if ((valid_acc[-1]-valid_acc[-2]) < EARLYTERM_EPS):\n",
    "                        break\n",
    "            \"\"\"\n",
    "        print()\n",
    "\n",
    "        #try:\n",
    "        #    saver\n",
    "        #except NameError:\n",
    "        #    saver = tf.train.Saver()\n",
    "        saver.save(sess, './models/googlenet_trafficsign.ckpt')\n",
    "        print(\"Model saved\")\n",
    "\n",
    "t1_stop = time.perf_counter()\n",
    "t2_stop = time.process_time()\n",
    "print(\"- - - - - - -\")\n",
    "print(\"Elapsed time: %.1f [min]\" % ((t1_stop-t1_start)/60))\n",
    "print(\"CPU process time: %.1f [min]\" % ((t2_stop-t2_start)/60))\n",
    " \n",
    "#\n",
    "# Plot Learning Curves\n",
    "#\n",
    "fig4 = plt.figure(figsize=(15,5))\n",
    "plt.plot(train_loss, label='Training', color='dodgerblue')\n",
    "plt.plot([(i+1) * int(num_examples / BATCH_SIZE) for i in range(EPOCHS)], valid_loss, label='Validation', color='indianred')\n",
    "plt.title('Learning Curves', fontsize=15)\n",
    "plt.xlabel('Epoch', fontsize=15)\n",
    "plt.ylabel('Loss', fontsize=15)\n",
    "plt.gcf().set_size_inches(15, 12)\n",
    "plt.legend()\n",
    "#plt.tight_layout()\n",
    "plt.savefig('TrafficSigns_GoogLeNet_LearningCurve.png', dpi=100)\n",
    "plt.show()    \n",
    "\n",
    "#\n",
    "# Plot accuracy evolution \n",
    "#\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "plt.plot(train_acc, label='Training', color='dodgerblue')\n",
    "plt.plot([(i+1) * int(num_examples / BATCH_SIZE) for i in range(EPOCHS)], valid_acc, label='Validation', color='indianred')\n",
    "plt.title('Learning Curves', fontsize=15)\n",
    "plt.xlabel('Epoch', fontsize=15)\n",
    "plt.ylabel('Accuracy', fontsize=15)\n",
    "plt.gcf().set_size_inches(15, 12)\n",
    "plt.legend()\n",
    "#plt.tight_layout()\n",
    "plt.savefig('TrafficSigns_GoogLeNet_AccuracyCurve.png', dpi=100)\n",
    "plt.show()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.4 Model Performance on Test Images\n",
    "\n",
    "Apply the validted model on the test set and predict traffic-sizn class ID. Analyze performance to meet minimum accuracy of `> 95%`. \n",
    "\n",
    "There are two test modes, using pickled test data & using traffic sign images from the German traffic sign data-base. \n",
    "Obtain the top-5 detected class IDs along with the detection prbabilities (`softmax` values).\n",
    "\n",
    "---\n",
    "\n",
    "### 2.4.1 Internal Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate the accuracy for these 5 new images. \n",
    "### For example, if the model predicted 1 out of 5 signs correctly, it's 20% accurate on these new images.\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, './models/googlenet_trafficsign.ckpt')\n",
    "    train_accuracy, _ = evaluate(X_trn, y_trn)\n",
    "    valid_accuracy, _ = evaluate(X_val, y_val)\n",
    "    test_accuracy, _ = evaluate(X_tst, y_tst)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))\n",
    "    \n",
    "    # test data detected probabilities\n",
    "    test_logits = sess.run(logits, feed_dict={x: X_tst})\n",
    "    test_probs = sess.run(tf.nn.softmax(test_logits))\n",
    "    top5_probs, top5_indices = sess.run(tf.nn.top_k(test_probs, k=5))\n",
    "\n",
    "#\n",
    "# Plot LeNet5 accuracy comaprisons across train/validation/test data-set\n",
    "#\n",
    "tick_labels = [\"Training\", \"Validation\", \"Testing\"]\n",
    "fig6 = plt.figure()\n",
    "plt.bar(range(3), [train_accuracy, valid_accuracy, test_accuracy])\n",
    "plt.xlabel('Data Set')\n",
    "plt.ylabel('GoogLeNet Accuracy')\n",
    "plt.xticks(range(3), tick_labels)\n",
    "for x_,y_ in zip(range(3), [train_accuracy, valid_accuracy, test_accuracy]):\n",
    "    plt.text(x_ - 0.1, y_, '%.3f'%y_)\n",
    "plt.savefig('TrafficSigns_GoogLeNet_AccuracyCompare.png', dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2 Output Test Top-5 Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Top-5 Analysis for test images\n",
    "#print(tf.metrics.average_precision_at_k(y_tst,test_probs))\n",
    "\n",
    "\n",
    "\n",
    "### Run the predictions here and use the model to output the prediction for each image.\n",
    "### Make sure to pre-process the images with the same pre-processing pipeline used earlier.\n",
    "### Feel free to use as many code cells as needed.\n",
    "### Load the images and plot them here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "#\n",
    "# show traffic sign training images in 8x8 grid\n",
    "#\n",
    "\n",
    "# un-normalize test images for display\n",
    "X_ = (X_tst+1.) * 128.\n",
    "\n",
    "N = 4\n",
    "select_images = np.random.randint(1,n_test,N*N) # use the ones selected/displayed above\n",
    "fig5 = plt.figure()\n",
    "plt.subplots(figsize=(32,32))\n",
    "#plt.suptitle(\"Illustrative Training Samples with Traffic-Sign Boundary Annotation\", size='xx-large')\n",
    "for row in range(N):\n",
    "    for col in range(N):\n",
    "        idx = N*row+col\n",
    "        \n",
    "        # plot traffic sign with detection probability\n",
    "        ax = plt.subplot(N,N,idx+1)        \n",
    "        plt.imshow(X_[select_images[idx]])\n",
    "        plt.xlabel('Image size {}'.format(X_train_size[select_images[idx]]), size='xx-large')\n",
    "        # traffic sign coordinates scaled to 32x32\n",
    "        x1, y1, x2, y2 = X_test_loc[select_images[idx]]\n",
    "        x1 *= 32/X_test_size[select_images[idx]][0] \n",
    "        x2 *= 32/X_test_size[select_images[idx]][0] \n",
    "        y1 *= 32/X_test_size[select_images[idx]][1] \n",
    "        y2 *= 32/X_test_size[select_images[idx]][1] \n",
    "        lbl = top5_indices[select_images[idx]][0]\n",
    "        prob = top5_probs[select_images[idx]][0]\n",
    "               \n",
    "        if (lbl == y_tst[select_images[idx]]): # correct detect GREEN\n",
    "            ax.add_patch(patches.Rectangle((x1,y1), x2-x1, y2-y1, color='lawngreen', linewidth=5, fill=False))\n",
    "            plt.text(x1+.5,y1+1.75,\"ID: {} -- {:.2f}%\".format(lbl, prob*100), fontsize=30, bbox=dict(facecolor='lawngreen', alpha=0.85))\n",
    "        else : # incorrect detect RED\n",
    "            #print(y_tst[select_images[idx]], \" : \", top5_indices[select_images[idx]])\n",
    "            ax.add_patch(patches.Rectangle((x1,y1), x2-x1, y2-y1, color='red', linewidth=5, fill=False))\n",
    "            plt.text(x1+.5,y1+1.75,\"ID: {} -- {:.2f}%\".format(lbl, prob*100), fontsize=30, bbox=dict(facecolor='red', alpha=0.85))\n",
    "            plt.text(x1+.5,y1+3.75,\"ID: {}\".format(y_tst[select_images[idx]]), fontsize=30, bbox=dict(facecolor='lawngreen', alpha=0.85))\n",
    "        plt.text(x1+.5,y1-1,\"{}\".format(signname_hash[str(lbl)]), fontsize=30, bbox=dict(facecolor='cyan', alpha=1.))\n",
    "\n",
    "        \"\"\"\n",
    "        # plot top-5 probabilities (softmax values)\n",
    "        ax = plt.subplot(2*N,N,idx+2)        \n",
    "        rects = ax.barh(np.arange(5), top5_probs[select_images[idx]], align='center', height=.5, color='skyblue', ec='dodgerblue')\n",
    "        for rect in rects:\n",
    "            width = int(rect.get_width())\n",
    "            rankStr = str(width)+\"%\"\n",
    "            if (width < 15):\n",
    "                xloc = width + 1\n",
    "                clr = 'black'\n",
    "                align = 'left'\n",
    "            else:\n",
    "                xloc = 0.98*width\n",
    "                clr = 'white'\n",
    "                align = 'right'\n",
    "        yloc = rect.get_y() + rect.get_height()/2.0\n",
    "        label = ax.text(xloc, yloc, rankStr, horizontalalignment=align,\n",
    "                 verticalalignment='center', color='black', size=8, weight='bold',\n",
    "                 clip_on=True)\n",
    "        ax.invert_yaxis()\n",
    "        ax.axis('off')\n",
    "        \"\"\"\n",
    "plt.tight_layout()\n",
    "plt.savefig('TrafficSigns_GoogLeNet_TestImages.png', dpi=100)\n",
    "plt.show()\n",
    "plt.draw()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top-5 Detection Probabilities `softmax[logits]` for sample tets images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Print out the top five softmax probabilities for the predictions on the German traffic sign images found on the web. \n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "# select one \"correct\" & \"incorrect\" detection sample\n",
    "\n",
    "incorrect_idx = (next(idx for idx in range(len(y_tst)) if ((top5_indices[idx][0]!=y_tst[idx]) and (top5_probs[idx][1]>1e-3)) ))\n",
    "correct_idx = (next(idx for idx in range(len(y_tst)) if ((top5_indices[idx][0]==y_tst[idx]) and (top5_probs[idx][1]>1e-3)) ))\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.subplots(figsize=(16,16))\n",
    "\n",
    "# plot traffic sign with CORRECT detection probability\n",
    "ax = plt.subplot(2,2,1)        \n",
    "plt.imshow(X_[correct_idx])\n",
    "plt.xlabel('Image size {}'.format(X_train_size[correct_idx]), size='xx-large')\n",
    "# traffic sign coordinates scaled to 32x32\n",
    "x1, y1, x2, y2 = X_test_loc[correct_idx]\n",
    "x1 *= 32/X_test_size[correct_idx][0] \n",
    "x2 *= 32/X_test_size[correct_idx][0] \n",
    "y1 *= 32/X_test_size[correct_idx][1] \n",
    "y2 *= 32/X_test_size[correct_idx][1] \n",
    "lbl = top5_indices[correct_idx][0]\n",
    "prob = top5_probs[correct_idx][0]\n",
    "if (lbl == y_tst[correct_idx]): # correct detect GREEN\n",
    "    ax.add_patch(patches.Rectangle((x1,y1), x2-x1, y2-y1, color='lawngreen', linewidth=5, fill=False))\n",
    "    plt.text(x1+.5,y1+1.75,\"ID: {} -- {:.2f}%\".format(lbl, prob*100), fontsize=30, bbox=dict(facecolor='lawngreen', alpha=0.85))\n",
    "else : # incorrect detect RED\n",
    "    #print(y_tst[select_images[idx]], \" : \", top5_indices[select_images[idx]])\n",
    "    ax.add_patch(patches.Rectangle((x1,y1), x2-x1, y2-y1, color='red', linewidth=5, fill=False))\n",
    "    plt.text(x1+.5,y1+1.75,\"ID: {} -- {:.2f}%\".format(lbl, prob*100), fontsize=30, bbox=dict(facecolor='red', alpha=0.85))\n",
    "    plt.text(x1+.5,y1+3.75,\"ID: {}\".format(y_tst[correct_idx]), fontsize=30, bbox=dict(facecolor='lawngreen', alpha=0.85))\n",
    "plt.text(x1+.5,y1-1,\"{}\".format(signname_hash[str(lbl)]), fontsize=30, bbox=dict(facecolor='cyan', alpha=1.))\n",
    "ax1 = plt.subplot(2,2,2)\n",
    "plt.xlabel('Correct Detection -- top-5 detection probabilities', size='xx-large', color='darkgreen')\n",
    "scores = top5_probs[correct_idx]*100\n",
    "pos = np.arange(len(scores))\n",
    "rects = ax1.barh(pos, scores, align='center', height=.8, color='dodgerblue', ec='blue')\n",
    "# Lastly, write in the ranking inside each bar to aid in interpretation\n",
    "cnt = 0\n",
    "for rect in rects:\n",
    "    width = round(rect.get_width(),2)\n",
    "    rankStr = str(width)+\"% ID[\"+str(top5_indices[correct_idx][cnt])+\"]\"\n",
    "    if (width<10):xloc = width+10 \n",
    "    else: xloc = 0.98*width\n",
    "    clr = 'black'\n",
    "    align = 'right'\n",
    "    yloc = rect.get_y() + rect.get_height()/2.0\n",
    "    label = ax1.text(xloc, yloc, rankStr, horizontalalignment=align,\n",
    "                 verticalalignment='center', color='black', size=15, weight='bold',\n",
    "                 clip_on=True)\n",
    "    cnt += 1\n",
    "ax1.invert_yaxis()\n",
    "\n",
    "# plot traffic sign with INCORRECT detection probability\n",
    "ax3 = plt.subplot(2,2,3)        \n",
    "plt.imshow(X_[correct_idx])\n",
    "plt.xlabel('Image size {}'.format(X_train_size[incorrect_idx]), size='xx-large')\n",
    "# traffic sign coordinates scaled to 32x32\n",
    "x1, y1, x2, y2 = X_test_loc[incorrect_idx]\n",
    "x1 *= 32/X_test_size[incorrect_idx][0] \n",
    "x2 *= 32/X_test_size[incorrect_idx][0] \n",
    "y1 *= 32/X_test_size[incorrect_idx][1] \n",
    "y2 *= 32/X_test_size[incorrect_idx][1] \n",
    "lbl = top5_indices[incorrect_idx][0]\n",
    "prob = top5_probs[incorrect_idx][0]\n",
    "if (lbl == y_tst[correct_idx]): # correct detect GREEN\n",
    "    ax3.add_patch(patches.Rectangle((x1,y1), x2-x1, y2-y1, color='lawngreen', linewidth=5, fill=False))\n",
    "    plt.text(x1+.5,y1+1.75,\"ID: {} -- {:.2f}%\".format(lbl, prob*100), fontsize=30, bbox=dict(facecolor='lawngreen', alpha=0.85))\n",
    "else : # incorrect detect RED\n",
    "    #print(y_tst[select_images[idx]], \" : \", top5_indices[select_images[idx]])\n",
    "    ax3.add_patch(patches.Rectangle((x1,y1), x2-x1, y2-y1, color='red', linewidth=5, fill=False))\n",
    "    plt.text(x1+.5,y1+1.75,\"ID: {} -- {:.2f}%\".format(lbl, prob*100), fontsize=30, bbox=dict(facecolor='red', alpha=0.85))\n",
    "    plt.text(x1+.5,y1+3.75,\"ID: {}\".format(y_tst[incorrect_idx]), fontsize=30, bbox=dict(facecolor='lawngreen', alpha=0.85))\n",
    "plt.text(x1+.5,y1-1,\"{}\".format(signname_hash[str(lbl)]), fontsize=30, bbox=dict(facecolor='cyan', alpha=1.))\n",
    "ax2 = plt.subplot(2,2,4)\n",
    "plt.xlabel('In-correct Detection -- top-5 detection probabilities', size='xx-large', color='red')\n",
    "scores = top5_probs[incorrect_idx]*100\n",
    "pos = np.arange(len(scores))\n",
    "rects = ax2.barh(pos, scores, align='center', height=.8, color='dodgerblue', ec='blue')\n",
    "# Lastly, write in the ranking inside each bar to aid in interpretation\n",
    "cnt = 0\n",
    "for rect in rects:\n",
    "    width = round(rect.get_width(),2)\n",
    "    rankStr = str(width)+\"% ID[\"+str(top5_indices[incorrect_idx][cnt])+\"]\"\n",
    "    if (width<10):xloc = width+1 \n",
    "    else: xloc = 0.98*width\n",
    "    clr = 'black'\n",
    "    align = 'right'\n",
    "    yloc = rect.get_y() + rect.get_height()/2.0\n",
    "    label = ax2.text(xloc, yloc, rankStr, horizontalalignment=align,\n",
    "                 verticalalignment='center', color='black', size=15, weight='bold',\n",
    "                 clip_on=True)\n",
    "    cnt += 1\n",
    "ax2.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('TrafficSigns_GoogLeNet_TestImages_Top5Probs.png', dpi=100)\n",
    "plt.show()\n",
    "plt.draw()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 German Traffic Sign DB\n",
    "\n",
    "**Using Test Image Data-set**\n",
    "\n",
    "[Test Images](http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset#Downloads)\n",
    "\n",
    "Read pre-processed image from pickled cache and apply classifier network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Read processed data-set from pickle\n",
    "#\n",
    "def print_stats(X, arrayname = ''):\n",
    "    print(arrayname, \": {StdDev, Mean, Range, Min, Max} =\\n\\t\",X.std(axis=(0,1,2)), X.mean(axis=(0,1,2)), X.ptp(), X.min(axis=(0,1,2)), X.max(axis=(0,1,2)))    \n",
    "    return\n",
    "\n",
    "# Load pickled normalized-data\n",
    "pickle_file = './dataset/GTSRBData_processed.p'\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    pickle_data = pickle.load(f)\n",
    "    \n",
    "    GTSRB_test_images = pickle_data['test_images']\n",
    "    X_test = pickle_data['test_norm']\n",
    "    y_test = pickle_data['labels']\n",
    "    W = pickle_data['width']\n",
    "    H = pickle_data['height']\n",
    "    X1 = pickle_data['X1']\n",
    "    Y1 = pickle_data['Y1']\n",
    "    X2 = pickle_data['X2']\n",
    "    Y2 = pickle_data['Y2']\n",
    "    del pickle_data  # Free up memory\n",
    "\n",
    "#\n",
    "# Dataset summary\n",
    "#\n",
    "total_samples = len(X_test)\n",
    "n_classes = len(set(y_test))\n",
    "\n",
    "print(\"Unique labels = \",len(set(y_test)))\n",
    "print(\"Test set: \")\n",
    "print(\"\\t Number of samples = \",len(X_test), \":({0:.2f}%)\".format(len(X_test)/total_samples*100))\n",
    "print(\"\\t Image dimension   = \",X_test.shape[1],\"x\", X_test.shape[2],\"x\", X_test.shape[3])\n",
    "print(\"\\t Data types (X, y) = \",X_test.dtype,\",\", y_test.dtype)\n",
    "print(\"\\t Data range (X, y) = \",np.ptp(X_test),\",\", np.ptp(y_test))\n",
    "\n",
    "print('Data loaded ...')\n",
    "\n",
    "print('\\nData Summary Statistics:')\n",
    "print_stats(X_test, \"test\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Apply LeNet classifier to GTSRB data-set\n",
    "#\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, './models/googlenet_trafficsign.ckpt')\n",
    "    test_accuracy,_ = evaluate(X_test, y_test)\n",
    "    # test data detected probabilities\n",
    "    test_logits = sess.run(logits, feed_dict={x: X_test})\n",
    "    test_probs = sess.run(tf.nn.softmax(test_logits))\n",
    "    top5_probs, top5_indices = sess.run(tf.nn.top_k(test_probs, k=5))\n",
    "\n",
    "accuracy = [test_accuracy]\n",
    "tick_labels = [\"Testing set\"]\n",
    "plt.bar(range(1), accuracy)\n",
    "plt.xlabel('Data set')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(range(1), tick_labels)\n",
    "for x_,y_ in zip(range(1), accuracy):\n",
    "    plt.text(x_ - 0.1, y_, '%.3f'%y_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top-5 Detection Probabilities `softmax[logits]` for sample test images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Print out the top five softmax probabilities for the predictions on the German traffic sign images found on the web. \n",
    "### Feel free to use as many code cells as needed.\n",
    "# un-normalize test images for display\n",
    "X_ = (X_test+1.) * 128.\n",
    "\n",
    "# select one \"correct\" & \"incorrect\" detection sample\n",
    "incorrect_idx = (next(idx for idx in range(len(y_test)) if ((top5_indices[idx][0]!=y_test[idx]) and (top5_probs[idx][1]>1e-3)) ))\n",
    "correct_idx = (next(idx for idx in range(len(y_test)) if ((top5_indices[idx][0]==y_test[idx]) and (top5_probs[idx][1]>1e-3)) ))\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.subplots(figsize=(16,16))\n",
    "\n",
    "# plot traffic sign with CORRECT detection probability\n",
    "ax = plt.subplot(2,2,1)        \n",
    "plt.imshow(X_[correct_idx])\n",
    "plt.xlabel('Image size {}x{}'.format(W[correct_idx],H[correct_idx]), size='xx-large')\n",
    "# traffic sign coordinates scaled to 32x32\n",
    "x1 = X1[correct_idx] * 32/W[correct_idx] \n",
    "x2 = X2[correct_idx] * 32/W[correct_idx]\n",
    "y1 = Y1[correct_idx] * 32/H[correct_idx] \n",
    "y2 = Y2[correct_idx] * 32/H[correct_idx] \n",
    "lbl = top5_indices[correct_idx][0]\n",
    "prob = top5_probs[correct_idx][0]\n",
    "if (lbl == y_test[correct_idx]): # correct detect GREEN\n",
    "    ax.add_patch(patches.Rectangle((x1,y1), x2-x1, y2-y1, color='lawngreen', linewidth=5, fill=False))\n",
    "    plt.text(x1+.5,y1+1.75,\"ID: {} -- {:.2f}%\".format(lbl, prob*100), fontsize=30, bbox=dict(facecolor='lawngreen', alpha=0.85))\n",
    "else : # incorrect detect RED\n",
    "    #print(y_tst[select_images[idx]], \" : \", top5_indices[select_images[idx]])\n",
    "    ax.add_patch(patches.Rectangle((x1,y1), x2-x1, y2-y1, color='red', linewidth=5, fill=False))\n",
    "    plt.text(x1+.5,y1+1.75,\"ID: {} -- {:.2f}%\".format(lbl, prob*100), fontsize=30, bbox=dict(facecolor='red', alpha=0.85))\n",
    "    plt.text(x1+.5,y1+3.75,\"ID: {}\".format(y_test[correct_idx]), fontsize=30, bbox=dict(facecolor='lawngreen', alpha=0.85))\n",
    "plt.text(x1+.5,y1-1,\"{}\".format(signname_hash[str(lbl)]), fontsize=30, bbox=dict(facecolor='cyan', alpha=1.))\n",
    "ax1 = plt.subplot(2,2,2)\n",
    "plt.xlabel('Correct Detection -- top-5 detection probabilities', size='xx-large', color='darkgreen')\n",
    "scores = top5_probs[correct_idx]*100\n",
    "pos = np.arange(len(scores))\n",
    "rects = ax1.barh(pos, scores, align='center', height=.8, color='dodgerblue', ec='blue')\n",
    "# Lastly, write in the ranking inside each bar to aid in interpretation\n",
    "cnt = 0\n",
    "for rect in rects:\n",
    "    width = round(rect.get_width(),2)\n",
    "    rankStr = str(width)+\"% ID[\"+str(top5_indices[correct_idx][cnt])+\"]\"\n",
    "    if (width<10):xloc = width+10 \n",
    "    else: xloc = 0.98*width\n",
    "    clr = 'black'\n",
    "    align = 'right'\n",
    "    yloc = rect.get_y() + rect.get_height()/2.0\n",
    "    label = ax1.text(xloc, yloc, rankStr, horizontalalignment=align,\n",
    "                 verticalalignment='center', color='black', size=15, weight='bold',\n",
    "                 clip_on=True)\n",
    "    cnt += 1\n",
    "ax1.invert_yaxis()\n",
    "\n",
    "# plot traffic sign with INCORRECT detection probability\n",
    "ax3 = plt.subplot(2,2,3)        \n",
    "plt.imshow(X_[incorrect_idx])\n",
    "plt.xlabel('Image size {}x{}'.format(W[incorrect_idx],H[incorrect_idx]), size='xx-large')\n",
    "# traffic sign coordinates scaled to 32x32\n",
    "x1 = X1[incorrect_idx] * 32/W[incorrect_idx] \n",
    "x2 = X2[incorrect_idx] * 32/W[incorrect_idx]\n",
    "y1 = Y1[incorrect_idx] * 32/H[incorrect_idx] \n",
    "y2 = Y2[incorrect_idx] * 32/H[incorrect_idx] \n",
    "lbl = top5_indices[incorrect_idx][0]\n",
    "prob = top5_probs[incorrect_idx][0]\n",
    "if (lbl == y_test[incorrect_idx]): # correct detect GREEN\n",
    "    ax3.add_patch(patches.Rectangle((x1,y1), x2-x1, y2-y1, color='lawngreen', linewidth=5, fill=False))\n",
    "    plt.text(x1+.5,y1+1.75,\"ID: {} -- {:.2f}%\".format(lbl, prob*100), fontsize=30, bbox=dict(facecolor='lawngreen', alpha=0.85))\n",
    "else : # incorrect detect RED\n",
    "    #print(y_tst[select_images[idx]], \" : \", top5_indices[select_images[idx]])\n",
    "    ax3.add_patch(patches.Rectangle((x1,y1), x2-x1, y2-y1, color='red', linewidth=5, fill=False))\n",
    "    plt.text(x1+.5,y1+1.75,\"ID: {} -- {:.2f}%\".format(lbl, prob*100), fontsize=30, bbox=dict(facecolor='red', alpha=0.85))\n",
    "    plt.text(x1+.5,y1+3.75,\"ID: {}\".format(y_test[incorrect_idx]), fontsize=30, bbox=dict(facecolor='lawngreen', alpha=0.85))\n",
    "plt.text(x1+.5,y1-1,\"{}\".format(signname_hash[str(lbl)]), fontsize=30, bbox=dict(facecolor='cyan', alpha=1.))\n",
    "ax2 = plt.subplot(2,2,4)\n",
    "plt.xlabel('In-correct Detection -- top-5 detection probabilities', size='xx-large', color='red')\n",
    "scores = top5_probs[incorrect_idx]*100\n",
    "pos = np.arange(len(scores))\n",
    "rects = ax2.barh(pos, scores, align='center', height=.8, color='dodgerblue', ec='blue')\n",
    "# Lastly, write in the ranking inside each bar to aid in interpretation\n",
    "cnt = 0\n",
    "for rect in rects:\n",
    "    width = round(rect.get_width(),2)\n",
    "    rankStr = str(width)+\"% ID[\"+str(top5_indices[incorrect_idx][cnt])+\"]\"\n",
    "    if (width<10):xloc = width+10 \n",
    "    else: xloc = 0.98*width\n",
    "    clr = 'black'\n",
    "    align = 'right'\n",
    "    yloc = rect.get_y() + rect.get_height()/2.0\n",
    "    label = ax2.text(xloc, yloc, rankStr, horizontalalignment=align,\n",
    "                 verticalalignment='center', color='black', size=15, weight='bold',\n",
    "                 clip_on=True)\n",
    "    cnt += 1\n",
    "ax2.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('TrafficSigns_GoogLeNet_GTSRBTestImages_Top5Probs.png', dpi=100)\n",
    "plt.show()\n",
    "plt.draw()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.5 Visualizing the Neural Network State (`weights`) with Test Images\n",
    "\n",
    " This Section is not required to complete but acts as an additional excersise for understaning the output of a neural network's weights. While neural networks can be a great learning device they are often referred to as a black box. We can understand what the weights of a neural network look like better by plotting their feature maps. After successfully training your neural network you can see what it's feature maps look like by plotting the output of the network's weight layers in response to a test stimuli image. From these plotted feature maps, it's possible to see what characteristics of an image the network finds interesting. For a sign, maybe the inner network feature maps react with high activation to the sign's boundary outline or to the contrast in the sign's painted symbol.\n",
    "\n",
    " Provided for you below is the function code that allows you to get the visualization output of any tensorflow weight layer you want. The inputs to the function should be a stimuli image, one used during training or a new one you provided, and then the tensorflow variable name that represents the layer's state during the training process, for instance if you wanted to see what the [LeNet lab's](https://classroom.udacity.com/nanodegrees/nd013/parts/fbf77062-5703-404e-b60c-95b78b2f3f9e/modules/6df7ae49-c61c-4bb2-a23e-6527e69209ec/lessons/601ae704-1035-4287-8b11-e2c2716217ad/concepts/d4aca031-508f-4e0b-b493-e7b706120f81) feature maps looked like for it's second convolutional layer you could enter conv2 as the tf_activation variable.\n",
    "\n",
    "For an example of what feature map outputs look like, check out NVIDIA's results in their paper [End-to-End Deep Learning for Self-Driving Cars](https://devblogs.nvidia.com/parallelforall/deep-learning-self-driving-cars/) in the section Visualization of internal CNN State. NVIDIA was able to show that their network's inner weights had high activations to road boundary lines by comparing feature maps from an image with a clear path to one without. Try experimenting with a similar test to show that your trained network's weights are looking for interesting features, whether it's looking at differences in feature maps from images with or without a sign, or even what feature maps look like in a trained network vs a completely untrained one on the same sign image.\n",
    "\n",
    "<figure>\n",
    " <img src=\"visualize_cnn.png\" width=\"380\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Your output should look something like this (above)</p> \n",
    " </figcaption>\n",
    "</figure>\n",
    " <p></p> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualize your network's feature maps here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "# image_input: the test image being fed into the network to produce the feature maps\n",
    "# tf_activation: should be a tf variable name used during your training procedure that represents the calculated state of a specific weight layer\n",
    "# activation_min/max: can be used to view the activation contrast in more detail, by default matplot sets min and max to the actual min and max values of the output\n",
    "# plt_num: used to plot out multiple different weight feature map sets on the same block, just extend the plt number for each new feature map entry\n",
    "\n",
    "def outputFeatureMap(image_input, tf_activation, activation_min=-1, activation_max=-1 ,plt_num=1):\n",
    "    # Here make sure to preprocess your image_input in a way your network expects\n",
    "    # with size, normalization, ect if needed\n",
    "    # image_input =\n",
    "    # Note: x should be the same name as your network's tensorflow data placeholder variable\n",
    "    # If you get an error tf_activation is not defined it may be having trouble accessing the variable from inside a function\n",
    "    activation = tf_activation.eval(session=sess,feed_dict={x : image_input})\n",
    "    featuremaps = activation.shape[3]\n",
    "    plt.figure(plt_num, figsize=(15,15))\n",
    "    for featuremap in range(featuremaps):\n",
    "        plt.subplot(6,8, featuremap+1) # sets the number of feature maps to show on each row and column\n",
    "        plt.title('FeatureMap ' + str(featuremap)) # displays the feature map number\n",
    "        if activation_min != -1 & activation_max != -1:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", vmin =activation_min, vmax=activation_max, cmap=\"gray\")\n",
    "        elif activation_max != -1:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", vmax=activation_max, cmap=\"gray\")\n",
    "        elif activation_min !=-1:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", vmin=activation_min, cmap=\"gray\")\n",
    "        else:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", cmap=\"gray\")\n",
    "    plt.savefig('TrafficSigns_GoogLeNet_Layer1_Visualization.png', dpi=100)\n",
    "            \n",
    "with tf.Session() as sess:\n",
    "#sess = tf.InteractiveSession()\n",
    "    saver.restore(sess, './models/googlenet_trafficsign.ckpt')\n",
    "\n",
    "    # select GoogLeNet 2B layer weights as applied to GTSRB image #5\n",
    "    conv1 = layers.conv2d(inputs, 64, [3, 3], stride = 2) # 16x16x64    \n",
    "    inception_2a = Inception(conv1, 64, 96, 128, 16, 32, 32) # 16x16x256\n",
    "    inception_2b = Inception(inception_2a, 128, 128, 192, 32, 96, 64) # 16x16x480\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    print(conv1)\n",
    "    outputFeatureMap(np.reshape(X_[5],[1,32,32,3]), inception_2b)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(X_[5])\n",
    "    plt.savefig('TrafficSigns_GoogLeNet_Layer1_Visualization_Sample.png', dpi=100)\n",
    "\n",
    "#sess.close()            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
