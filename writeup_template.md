{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "\n",
    "## Project: **Traffic Sign Classifier** \n",
    "***\n",
    "This is a ML based traffic sign classification implementation using a variety of CNN network architectures with keras framework. \n",
    "\n",
    "The project implementation is structured as follows. \n",
    "\n",
    "---\n",
    ">**Traffic Sign Classification Project**\n",
    "\n",
    ">1. Data Process\n",
    ">    1. Data is analyzed to highlight low-frequency categories and suitably augmented. \n",
    ">    2. The augmented data is then normalized before pickling.\n",
    ">2. ML network classifiers\n",
    ">    1. Three differnt architectures are used to compare classifier performance. The 3 netowrk architectures chosen are LeNet, AlexNext and GoogLeNet. \n",
    "***\n",
    "\n",
    "\n",
    "## 1. Data Processor\n",
    "\n",
    "**Test data source & references**\n",
    "\n",
    "1. Data-set from GTSRB web-site as per project requirements -- [German Traffic Sign Repo](benchmark.ini.rub.de/?section=gtsrb&subsection=dataset#Imageformat)\n",
    "\n",
    "2. Network model examples were derived from github repos, especially the variant of AlexNet to fit the data-set constraints -- [liferlisiqi GitHub](https://github.com/liferlisiqi/Traffic-Sign-Classifier/blob/master/README.md) \n",
    "\n",
    "This program reads from data-source and performs bsic data analysis and summarization. It then normlaizes the data and chaches the normalized data sets into a pickle file for further network processing. \n",
    "\n",
    ">**Note**: Data normalization is applied to the given data-set as well as the downloaded German Traffic Sign data-base. See sections towards the end of this notebook for the GTSRB data-processing. \n",
    "\n",
    "Sample training data set visualization. \n",
    "<img src=\"./TrafficSigns.png\" alt=\"Sample Training Data Set\" width=450/>\n",
    "\n",
    "- - - - \n",
    "\n",
    "### 1.1 Data Augmentation\n",
    "Using data-augmentation to enlarge training set for a more generalized & robust network. \n",
    "\n",
    "Simple augmentation techniques are employed here which include\n",
    " \n",
    " 1. Small random image dithers: samples randomly perturbed in \n",
    "     - Position ([-2,2] pixels)\n",
    "     - Scale ([.9,1.1] ratio) and \n",
    "     - Rotation ([-15,+15] degrees)\n",
    "     \n",
    "Random selections of images with equal sampling from each traffic sign class ID are done with 1/3rd of the samples being applied with the dithers above. \n",
    "\n",
    "A simpler technique is to shuffle the selected training set and select each 1/3rd partition to apply the dithering. This is used to simplify the data augmentation process.\n",
    "\n",
    ">**Note**: For augmentation, only a 1/3 of the entire training set is chosen, so essentially each of the 3 augmentations are applied to only 1/9th of the original image training set. This is done primarily as a method to save on the disk-space as the combined data set now only consumes x1.33 of the original space.  \n",
    "\n",
    ">**Note**: The training image size & sign RoI locations are not modified after augmentation and replicated in the augmented training set as-is. The argument for this is that simply the dithered/scaled/rotated images are warped/scaled back to original size and hence the RoI ofr the labelled traffic sign should not vary by much, if at all. \n",
    "\n",
    "Following is a plot of the training data set after & before augmentation showing a \"more  uniform\" distribution of categories. \n",
    "<img src=\"./TrafficSigns_DataClassDistributions_BeforeAfter.png\" alt=\"Augmented Training Data Distribution\" width=450/>\n",
    "\n",
    "\n",
    "\n",
    "## 3. CNN Classifiers\n",
    "\n",
    "After daat-paugmentation & processing, 3 different architectures of CNN classifiers are tested. \n",
    "\n",
    "### 3.1 LeNet \n",
    "This program reads pre-processed data from pickled data-source and applies the LeNet model for traffic sign classification.\n",
    "The TensorFlow model is then pickled in the `./models` sub-directory for the final evaluation phase.  \n",
    "\n",
    ">**Strategy**: \n",
    "> 1. Training hyper-parameters were selected afetr a fair amount  of parameter sweeps but essentially are empirircal in the choice. The set values in this notebook perform with goo accuracy for the particular data-sets chosen for validation & testing. \n",
    "> 2. A drop-out scheme was chosen as a simpler mechanism to reduce weight variance rahter than L2-regularization or other more elaborate methods. \n",
    "> 3. An early training termination crietria was chosen to be when per-epoch training accuracy (measured on validation set) was found to decrease by $\\le \\epsilon=10^{-3}$. This was done primarily to shorten training wall-clock times for a model with *sufficient* accuracy for the particular classifier task.  \n",
    "> 4. Note that the early termination kicks in only after _a minimum number of epochs_ (chosen here to be $E = 15$) have been run. \n",
    "\n",
    "#### 3.1.1 LeNet Model Architecture\n",
    "\n",
    "Design and implement a deep learning model that learns to recognize traffic signs. Train and test your model on the [German Traffic Sign Dataset](http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset).\n",
    "\n",
    "The LeNet-5 implementation shown in the [classroom](https://classroom.udacity.com/nanodegrees/nd013/parts/fbf77062-5703-404e-b60c-95b78b2f3f9e/modules/6df7ae49-c61c-4bb2-a23e-6527e69209ec/lessons/601ae704-1035-4287-8b11-e2c2716217ad/concepts/d4aca031-508f-4e0b-b493-e7b706120f81) at the end of the CNN lesson is a solid starting point. You'll have to change the number of classes and possibly the preprocessing, but aside from that it's plug and play! \n",
    "\n",
    "With the LeNet-5 solution from the lecture, you should expect a validation set accuracy of about 0.89. To meet specifications, the validation set accuracy will need to be at least 0.93. It is possible to get an even higher accuracy, but 0.93 is the minimum for a successful project submission. \n",
    "\n",
    "There are various aspects to consider when thinking about this problem:\n",
    "\n",
    "- Neural network architecture (is the network over or underfitting?)\n",
    "- Play around preprocessing techniques (normalization, rgb to grayscale, etc)\n",
    "- Number of examples per label (some have more than others).\n",
    "- Generate fake data.\n",
    "\n",
    "Here is an example of a [published baseline model on this problem](http://yann.lecun.com/exdb/publis/pdf/sermanet-ijcnn-11.pdf). It's not required to be familiar with the approach used in the paper but, it's good practice to try to read papers like these.\n",
    "\n",
    ">**Note**: No padding is required for this implementation as the normalized data-set has be re-sized to 32 x 32.\n",
    "\n",
    ">**Note**: RGB images are used here, set `USE_GRAYSCALE = True` to use gray-scaled versions. \n",
    "\n",
    "#### 3.1.2 TensorFlow Environment Hyper-Parameters\n",
    "\n",
    "Re-shuffle data-set to remove hidden biases in labelled sequences\n",
    "\n",
    "**Hyperparameter Record** \n",
    "\n",
    "> *LeNet*: `USE_GRAYSCALE = False`, `EPOCHS = 50`, `BATCH_SIZE = 128`, `KEEP_PROB = .85`, `LEARN_RATE = 1e-3`, `USE_SGD = 'Adam'` \n",
    "\n",
    "#### 3.1.3 LeNet5 Network\n",
    "\n",
    "![LeNEt5 Architecture](./lenet_archdiagram.png)\n",
    "\n",
    "**Model Layer Architecture**\n",
    "\n",
    "Input data is a normalized RGB frame of size `32x32` pixels. The LeNet network base-layers can be used almost without modification. The only change of course is to modify the final fully-connected layer to detect `n_classes` number of categories in stead of teh standard 10 categories from LeNet's original implementation.  \n",
    "\n",
    "As implemented, the network below has the following layer organization: (derived from a Keras summary implementation of the network) \n",
    "\n",
    "#### 3.1.4 Model Performance on Test Images\n",
    "\n",
    "Apply the validted model on the test set and predict traffic-sizn class ID. Analyze performance to meet minimum accuracy of `> 95%`. \n",
    "\n",
    "There are two test modes, using pickled test data & using traffic sign images from the German traffic sign data-base. \n",
    "Obtain the top-5 detected class IDs along with the detection prbabilities (`softmax` values).\n",
    "\n",
    "LeNet Test Accuracy: \n",
    "<img src=\"./TrafficSigns_LeNet_AccuracyCompare.png\" alt=\"Convolutional Lane-marker Search\" width=450/>\n",
    "\n",
    "LeNet Top-5 Probability Performance: \n",
    "<img src=\"./TrafficSigns_LeNet_TestImages_Top5Probs.png\" alt=\"Convolutional Lane-marker Search\" width=450/>\n",
    "\n",
    "GTSRB Test Evaluation:\n",
    "<img src=\"./TrafficSigns_LeNet_GTSRBTestImages_Top5Probs.png\" alt=\"Convolutional Lane-marker Search\" width=450/>\n",
    "\n",
    "\n",
    "### 3.2 AlexNet\n",
    "\n",
    "This program reads pre-processed data from pickled data-source and applies the GoogLeNet Inceptionv3 model for traffic sign classification.\n",
    "The TensorFlow model is then pickled in the `./models` sub-directory for the final evaluation phase.  \n",
    "\n",
    ">**Strategy**: \n",
    "> 1. Training hyper-parameters were selected after a fair amount  of parameter sweeps but essentially are empirircal in the choice. The set values in this notebook perform with goo accuracy for the particular data-sets chosen for validation & testing. \n",
    "> 2. A L2 regularization scheme is chosen as in the standard AlexNet arhcitecture. \n",
    "> 3. An early training termination crietria was chosen to be when per-epoch training accuracy (measured on validation set) was found to decrease by $\\le \\epsilon=10^{-3}$. This was done primarily to shorten training wall-clock times for a model with *sufficient* accuracy for the particular classifier task.  \n",
    "> 4. Note that the early termination kicks in only after _a minimum number of epochs_ (chosen here to be $E = 15$) have been run. \n",
    "\n",
    "#### 3.2.1 AlexNet Model Architecture\n",
    "\n",
    "Design and implement a deep learning model that learns to recognize traffic signs. Train and test your model on the [German Traffic Sign Dataset](http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset).\n",
    "\n",
    "There are various aspects to consider when thinking about this problem:\n",
    "\n",
    "- Neural network architecture (is the network over or underfitting?)\n",
    "- Play around preprocessing techniques (normalization, rgb to grayscale, etc)\n",
    "- Number of examples per label (some have more than others).\n",
    "- Generate fake data.\n",
    "\n",
    ">**Note**: No padding is required for this implementation as the normalized data-set has be re-sized to 32 x 32.\n",
    "\n",
    ">**Note**: RGB images are used here, set `USE_GRAYSCALE = True` to use gray-scaled versions. \n",
    "\n",
    "#### 3.2.2 TensorFlow Environment Hyper-Parameters\n",
    "\n",
    "Re-shuffle data-set to remove hidden biases in labelled sequences\n",
    "\n",
    "**Hyperparameter Record** \n",
    "\n",
    "> *AlexNet*: `USE_GRAYSCALE = False`, `EPOCHS = 30`, `BATCH_SIZE = 128`, `KEEP_PROB = .5`, `LEARN_RATE = 5e-4`, `USE_SGD = 'Adam'`, `BETA=1e-5` \n",
    "\n",
    "#### 3.2.3 AlexNet Network\n",
    "\n",
    "![AlexNet Architecture](./alexnet2012_archdiagram.png)\n",
    "\n",
    "---\n",
    "**Model Layer Architecture**\n",
    "\n",
    "Input data is a normalized RGB frame of size `32x32` pixels. The AlexNet network base-layers can be used almost without modifications. The changes required are for the  final fully-connected layer to detect `n_classes` number of categories as well as some modifications to suit the in stead of teh standard 10 categories from LeNet's original implementation.  \n",
    "\n",
    "As implemented, the network below has the following layer organization: (derived from a Keras summary implementation of the network) \n",
    "\n",
    "#### 3.2.3 Train & Validate the Model\n",
    "\n",
    "Run the training data through the training pipeline to train the model.\n",
    "\n",
    "Before each epoch, shuffle the training set.\n",
    "\n",
    "After each epoch, measure the loss and accuracy of the validation set.\n",
    "\n",
    "A validation set can be used to assess how well the model is performing. A low accuracy on the training and validation\n",
    "sets imply underfitting. A high accuracy on the training set but low accuracy on the validation set implies overfitting.\n",
    "\n",
    "Save the model after training.\n",
    "\n",
    "AlexNet Accuracy Curve: \n",
    "<img src=\"./TrafficSigns_AlexNet_AccuracyCurve.png\" alt=\"Convolutional Lane-marker Search\" width=450/>\n",
    "\n",
    "#### 3.2.4 Model Performance on Test Images\n",
    "\n",
    "Apply the validted model on the test set and predict traffic-sizn class ID. Analyze performance to meet minimum accuracy of `> 95%`. \n",
    "\n",
    "There are two test modes, using pickled test data & using traffic sign images from the German traffic sign data-base. \n",
    "Obtain the top-5 detected class IDs along with the detection prbabilities (`softmax` values).\n",
    "\n",
    "AlexNet Test Accuracy Comparison: \n",
    "<img src=\"./TrafficSigns_AlexNet_AccuracyCompare.png\" alt=\"Convolutional Lane-marker Search\" width=450/>\n",
    "\n",
    "AlexNet Sample Test Output: \n",
    "<img src=\"./TrafficSigns_AlexNet_TestImages.png\" alt=\"Convolutional Lane-marker Search\" width=450/>\n",
    "\n",
    "AlexNet Top-5 Detection Probabilities:\n",
    "<img src=\"./TrafficSigns_AlexNet_TestImages_Top5Probs.png\" alt=\"Convolutional Lane-marker Search\" width=450/>\n",
    "\n",
    "GTSRB Classification Results: \n",
    "<img src=\"./TrafficSigns_AlexNet_GTSRBTestImages_Top5Probs.png\" alt=\"Convolutional Lane-marker Search\" width=450/>\n",
    "\n",
    "\n",
    "### 3.3 GoogLeNet\n",
    "This program reads pre-processed data from pickled data-source and applies the GoogLeNet Inceptionv3 model for traffic sign classification.\n",
    "The TensorFlow model is then pickled in the `./models` sub-directory for the final evaluation phase.  \n",
    "\n",
    ">**Strategy**: \n",
    "> 1. Training hyper-parameters were selected afetr a fair amount  of parameter sweeps but essentially are empirircal in the choice. The set values in this notebook perform with goo accuracy for the particular data-sets chosen for validation & testing. \n",
    "> 2. A drop-out regularization scheme is chosen as in the stndard Inceptionv3-based Googlenet arhcitecture. \n",
    "> 3. An early training termination crietria was chosen to be when per-epoch training accuracy (measured on validation set) was found to decrease by $\\le \\epsilon=10^{-3}$. This was done primarily to shorten training wall-clock times for a model with *sufficient* accuracy for the particular classifier task.  \n",
    "> 4. Note that the early termination kicks in only after _a minimum number of epochs_ (chosen here to be $E = 15$) have been run. \n",
    "\n",
    "#### 3.3.1 GoogLeNet Model Architecture\n",
    "\n",
    "Design and implement a deep learning model that learns to recognize traffic signs. Train and test your model on the [German Traffic Sign Dataset](http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset).\n",
    "\n",
    "There are various aspects to consider when thinking about this problem:\n",
    "\n",
    "- Neural network architecture (is the network over or underfitting?)\n",
    "- Play around preprocessing techniques (normalization, rgb to grayscale, etc)\n",
    "- Number of examples per label (some have more than others).\n",
    "- Generate fake data.\n",
    "\n",
    ">**Note**: No padding is required for this implementation as the normalized data-set has be re-sized to 32 x 32.\n",
    "\n",
    ">**Note**: RGB images are used here, set `USE_GRAYSCALE = True` to use gray-scaled versions. \n",
    "\n",
    "#### 3.3.2 TensorFlow Environment Hyper-Parameters\n",
    "\n",
    "Re-shuffle data-set to remove hidden biases in labelled sequences\n",
    "\n",
    "**Hyperparameter Record** \n",
    "\n",
    "> *GoogLeNet*: `USE_GRAYSCALE = False`, `EPOCHS = 35`, `BATCH_SIZE = 128`, `KEEP_PROB = .5`, `LEARN_RATE = 4e-4`, `USE_SGD = 'Adam'` \n",
    "\n",
    "#### 3.3.3 GoogLeNet Network (& Inception v3 Model)\n",
    "\n",
    "![GoogLeNet Architecture](./googlenet_archdiagram.png)\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "**Model Layer Architecture**\n",
    "\n",
    "Input data is a normalized RGB frame of size `32x32` pixels. The Inception v3 based GoogLeNet network base-layers can be used almost without modifications. The changes required are for the  final fully-connected layer to detect `n_classes` number of categories as well as some modifications to suit the in stead of the standard 10 categories from original implementation original implementation.  \n",
    "\n",
    "As implemented, the network below has the following layer organization: (derived from a Keras summary implementation of the network)  \n",
    ">**Note**:\n",
    "The following code has been used from the Keras documentation directly\n",
    "[Keras Application Inception v3](https://keras.io/applications/#inceptionv3)\n",
    "\n",
    "GoogLeNet Learning Curve: \n",
    "<img src=\"./TrafficSigns_GoogLeNet_LearningCurve.png\" alt=\"Convolutional Lane-marker Search\" width=450/>\n",
    "\n",
    "GoogLeNet Accuracy Curve: \n",
    "<img src=\"./TrafficSigns_GoogLeNet_AccuracyCurve.png\" alt=\"Convolutional Lane-marker Search\" width=450/>\n",
    "\n",
    "\n",
    "#### 3.3.4 Model Performance on Test Images\n",
    "\n",
    "Apply the validated model on the test set and predict traffic-sizn class ID. Analyze performance to meet minimum accuracy of `> 95%`. \n",
    "\n",
    "There are two test modes, using pickled test data & using traffic sign images from the German traffic sign data-base. \n",
    "Obtain the top-5 detected class IDs along with the detection prbabilities (`softmax` values).\n",
    "\n",
    "GoogLeNet Test Accuracy: \n",
    "<img src=\"./TrafficSigns_GoogLeNet_AccuracyCompare.png\" alt=\"Convolutional Lane-marker Search\" width=450/>\n",
    "\n",
    "GoogLeNet Top-5 Probability Performance: \n",
    "<img src=\"./TrafficSigns_GoogLeNet_TestImages.png\" alt=\"Convolutional Lane-marker Search\" width=450/>\n",
    "\n",
    "GTSRB Test Evaluation:\n",
    "<img src=\"./TrafficSigns_GoogLeNet_GTSRBTestImages_Top5Probs.png\" alt=\"Convolutional Lane-marker Search\" width=450/>\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Discussion\n",
    "\n",
    "A few enhancements that can make the implementation more robust:\n",
    "\n",
    "    1. Data-augmentation to account for poor lighting conditions may improve outlier performance for some hazy traffic sign images. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
